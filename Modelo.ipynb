{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "## Entrenamiento de modelo MLPClassifier; Escalado de características; División de datos en conjuntos de entrenamiento y validación; Evaluación del modelo con métricas de precisión y reporte; Generación de reporte de clasificación; Codificación de etiquetas de clase para target\n",
        "## ----------------------------------------------------------------\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import joblib\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler"
      ],
      "metadata": {
        "id": "OpSJRdzF__gU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sesgo (Skewness) y Curtosis (Kurtosis)\n",
        "\n",
        "### Sesgo (Skewness)\n",
        "\n",
        "La **sesgo** o *skewness* es una medida de la asimetría de la distribución de una variable aleatoria en torno a su media. Una distribución simétrica (por ejemplo, la normal) tiene skewness igual a cero; si la cola de la distribución se extiende más hacia la derecha (valores grandes), la skewness es positiva; si se extiende más hacia la izquierda, es negativa.\n",
        "\n",
        "#### Definición poblacional\n",
        "\n",
        "Para una variable aleatoria $X$ con esperanza $\\mu = \\mathbb{E}[X]$ y desviación estándar $\\sigma = \\sqrt{\\mathbb{E}[(X-\\mu)^2]}$, la skewness poblacional se define como el momento estandarizado de orden 3:\n",
        "\n",
        "$$\n",
        "\\gamma_1 \\;=\\; \\frac{\\mathbb{E}\\bigl[(X - \\mu)^3\\bigr]}{\\sigma^3}.\n",
        "$$\n",
        "\n",
        "- $$\\gamma_1 = 0$$: distribución perfectamente simétrica.  \n",
        "- $$\\gamma_1 > 0$$: cola derecha más larga o sesgo hacia la derecha.  \n",
        "- $$\\gamma_1 < 0$$: cola izquierda más larga o sesgo hacia la izquierda.  \n",
        "\n",
        "#### Estimador muestral\n",
        "\n",
        "Dado un conjunto de datos (muestra) $\\{x_i\\}_{i=1}^n$, con media muestral\n",
        "\n",
        "$$\n",
        "\\bar{x} = \\frac{1}{n}\\sum_{i=1}^n x_i\n",
        "$$\n",
        "\n",
        "y desviación estándar muestral\n",
        "\n",
        "$$\n",
        "\\hat{\\sigma} = \\sqrt{\\frac{1}{n}\\sum_{i=1}^n (x_i - \\bar{x})^2},\n",
        "$$\n",
        "\n",
        "un estimador común de skewness (no corregido por sesgo) es:\n",
        "\n",
        "$$\n",
        "g_1 \\;=\\; \\frac{\\frac{1}{n}\\sum_{i=1}^n (x_i - \\bar{x})^3}{\\left(\\frac{1}{n}\\sum_{i=1}^n (x_i - \\bar{x})^2\\right)^{3/2}}\n",
        "\\;=\\; \\frac{\\frac{1}{n}\\sum_{i=1}^n (x_i - \\bar{x})^3}{\\hat{\\sigma}^3}.\n",
        "$$\n",
        "\n",
        "> Nota: este estimador puede estar sesgado para muestras pequeñas. Existen correcciones (por ejemplo la definición de Fisher–Pearson), pero la forma básica anterior es la más usada para cálculo rápido y comprensión de la asimetría de los datos.\n",
        "\n",
        "#### ¿Para qué sirve la skewness?\n",
        "\n",
        "- Detectar asimetría en la distribución de datos: si el sesgo es significativo, puede influir en métodos que asumen normalidad o simetría (por ejemplo, en ciertas pruebas estadísticas o en estimaciones que dependen de la asimetría).  \n",
        "- Informar transformaciones de datos: al observar skewness alta (positiva o negativa), se puede considerar aplicar transformaciones (por ejemplo, log, raíz, Box–Cox) para aproximar una distribución más simétrica.  \n",
        "- Análisis exploratorio de datos (EDA): como parte de la descripción de la forma de la distribución, junto con media, mediana, varianza, curtosis, etc.\n",
        "\n",
        "---\n",
        "\n",
        "### Curtosis (Kurtosis)\n",
        "\n",
        "La **curtosis** o *kurtosis* mide la “forma de la cola” o el grado de concentración de la distribución en torno a la media (picudez y colas). Existen dos modos de definirla: la curtosis absoluta (o poblacional) y la **curtosis excesiva** (excess kurtosis), que compara con la distribución normal.\n",
        "\n",
        "#### Definición poblacional de curtosis\n",
        "\n",
        "Para la misma variable $$X$$ con media $$\\mu$$ y desviación estándar $$\\sigma$$, la curtosis poblacional se define como el momento estandarizado de orden 4:\n",
        "\n",
        "$$\n",
        "\\gamma_2 \\;=\\; \\frac{\\mathbb{E}\\bigl[(X - \\mu)^4\\bigr]}{\\sigma^4}.\n",
        "$$\n",
        "\n",
        "Muchos textos definen la **curtosis excesiva** restando 3 (el valor de la normal), de modo que:\n",
        "\n",
        "$$\n",
        "\\text{excess kurtosis} \\;=\\; \\gamma_2 - 3.\n",
        "$$\n",
        "\n",
        "- $$\\gamma_2 - 3 = 0$$: misma “picudez” y colas que la normal (mesocúrtica).  \n",
        "- $$\\gamma_2 - 3 > 0$$: colas más pesadas y pico más pronunciado (leptocúrtica).  \n",
        "- $$\\gamma_2 - 3 < 0$$: colas más ligeras y pico más achatado (platicúrtica).  \n",
        "\n",
        "#### Estimador muestral\n",
        "\n",
        "Para una muestra $\\{x_i\\}_{i=1}^n$ con media $\\bar{x}$ y desviación estándar $\\hat{\\sigma}$, un estimador sencillo de curtosis (no ajustado) es:\n",
        "\n",
        "$$\n",
        "g_2 \\;=\\; \\frac{\\frac{1}{n}\\sum_{i=1}^n (x_i - \\bar{x})^4}{\\left(\\frac{1}{n}\\sum_{i=1}^n (x_i - \\bar{x})^2\\right)^{2}}\n",
        "\\;=\\; \\frac{\\frac{1}{n}\\sum_{i=1}^n (x_i - \\bar{x})^4}{\\hat{\\sigma}^4}.\n",
        "$$\n",
        "\n",
        "La **curtosis excesiva muestral** se suele obtener restando 3:\n",
        "\n",
        "$$\n",
        "g_2 - 3.\n",
        "$$\n",
        "\n",
        "> Nota: existen fórmulas con corrección de sesgo para muestras pequeñas (por ejemplo, la fórmula de Fisher–Pearson ajustada con factores en función de $n$), pero la expresión anterior es la más directa para entender la “forma de la cola”.\n",
        "\n",
        "#### ¿Para qué sirve la curtosis?\n",
        "\n",
        "- Evaluar colas de la distribución: colas pesadas ($$\\gamma_2 - 3 > 0$$) indican mayor probabilidad de valores extremos, relevante en finanzas (riesgo de pérdidas grandes), calidad de procesos (valores atípicos), etc.  \n",
        "- Contrastar con normalidad: si un análisis asume normalidad, una curtosis muy distinta de 3 (excess kurtosis no nula) sugiere desviaciones que pueden afectar pruebas y modelos.  \n",
        "- Complemento al análisis de dispersión: junto con varianza y skewness, da una visión más completa de la forma de los datos.\n",
        "\n",
        "---\n",
        "\n",
        "### Resumen de fórmulas\n",
        "\n",
        "- **Skewness poblacional**:  \n",
        "  $$\n",
        "  \\gamma_1 = \\frac{\\mathbb{E}\\bigl[(X - \\mu)^3\\bigr]}{\\sigma^3}.\n",
        "  $$\n",
        "- **Skewness muestral (no corregida)**:  \n",
        "  $$\n",
        "  g_1 = \\frac{\\frac{1}{n}\\sum_{i=1}^n (x_i - \\bar{x})^3}{\\left(\\frac{1}{n}\\sum_{i=1}^n (x_i - \\bar{x})^2\\right)^{3/2}}.\n",
        "  $$\n",
        "\n",
        "- **Curtosis poblacional**:  \n",
        "  $$\n",
        "  \\gamma_2 = \\frac{\\mathbb{E}\\bigl[(X - \\mu)^4\\bigr]}{\\sigma^4}.\n",
        "  $$\n",
        "- **Curtosis muestral (no corregida)**:  \n",
        "  $$\n",
        "  g_2 = \\frac{\\frac{1}{n}\\sum_{i=1}^n (x_i - \\bar{x})^4}{\\left(\\frac{1}{n}\\sum_{i=1}^n (x_i - \\bar{x})^2\\right)^{2}}.\n",
        "  $$\n",
        "- **Excess kurtosis (poblacional)**: $$\\gamma_2 - 3$$.  \n",
        "- **Excess kurtosis (muestral)**: $$g_2 - 3$$.\n",
        "\n",
        "---\n",
        "\n",
        "### Notas adicionales\n",
        "\n",
        "- En la práctica, muchas librerías de análisis de datos (por ejemplo, `pandas`, `scipy.stats`, `statsmodels`) implementan funciones para calcular skewness y kurtosis, con opciones de corrección de sesgo para muestras pequeñas.\n",
        "- Para muestras pequeñas ($$n$$ bajo), conviene revisar si el estimador requiere corrección: algunas definiciones introducen factores multiplicativos en función de $$n$$ para que el estimador sea insesgado.\n",
        "- Interpretación:  \n",
        "  - Skewness alto (en valor absoluto) sugiere distribución asimétrica, lo que puede afectar la media y la mediana.  \n",
        "  - Curtosis alta indica riesgo de valores extremos; curtosis baja sugiere cola más finita.  \n",
        "- En análisis exploratorio, complementa con histogramas, gráficos de densidad y boxplots para visualizar asimetría y colas.\n"
      ],
      "metadata": {
        "id": "Ov5u3jTiB4dk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Cálculo de estadísticas de luz: media, desviación, skewness, kurtosis;\n",
        "## Procesamiento por lotes de datos de curvas de luz; Operaciones matemáticas con numpy, cálculos estadísticos;\n",
        "## Carga de datos con pandas\n",
        "## ----------------------------------------------------------------\n",
        "# Extracción de estadísticas incrementales\n",
        "def init_stats():\n",
        "    return {'n': 0, 'mean': 0.0, 'M2': 0.0, 'M3': 0.0, 'M4': 0.0, 'min': np.inf, 'max': -np.inf, 'det_sum': 0}\n",
        "\n",
        "# Calculos de momentos\n",
        "def update_moments(s, x, detected):\n",
        "    n1 = s['n']\n",
        "    n = n1 + 1\n",
        "    delta = x - s['mean']\n",
        "    delta_n = delta / n\n",
        "    mean = s['mean'] + delta_n\n",
        "    M2 = s['M2'] + delta * (x - mean)\n",
        "    M3 = s['M3'] + delta * (x - mean) * (n1 - 1) - 3 * delta_n * s['M2'] if n1 > 0 else 0.0\n",
        "    M4 = s['M4'] + delta * (x - mean) * (delta * (x - mean) * (n1**2 - 3*n1 + 3) / n**2 + 6 * s['M2'] / n) if n1 > 0 else 0.0\n",
        "    s['n'] = n; s['mean'] = mean; s['M2'] = M2; s['M3'] = M3; s['M4'] = M4\n",
        "    s['min'] = min(s['min'], x); s['max'] = max(s['max'], x); s['det_sum'] += detected\n",
        "\n",
        "stats = {}\n",
        "\n",
        "# Creación y modificación de dataframe de entrenamiento\n",
        "for chunk in pd.read_csv('training_set.csv.zip', compression='zip', chunksize=10**6):\n",
        "    for idx, row in chunk.iterrows():\n",
        "        obj = int(row['object_id'])\n",
        "        mjd = row['mjd']\n",
        "        band = int(row['passband'])\n",
        "        flux = row['flux']\n",
        "        detected = int(row['detected'])\n",
        "        if obj not in stats:\n",
        "            stats[obj] = {'t_min': mjd, 't_max': mjd, 'bands': set(), 'global': init_stats(), 'band_stats': {}}\n",
        "        obj_stats = stats[obj]\n",
        "        obj_stats['t_min'] = min(obj_stats['t_min'], mjd); obj_stats['t_max'] = max(obj_stats['t_max'], mjd)\n",
        "        update_moments(obj_stats['global'], flux, detected)\n",
        "        if band not in obj_stats['band_stats']:\n",
        "            obj_stats['band_stats'][band] = init_stats()\n",
        "        update_moments(obj_stats['band_stats'][band], flux, detected)\n",
        "        obj_stats['bands'].add(band)\n",
        "\n",
        "feature_list = []\n",
        "meta = pd.read_csv('training_set_metadata.csv')\n",
        "\n",
        "# Ciclo de calculo y guardado de datos\n",
        "for idx, row in meta.iterrows():\n",
        "    obj = int(row['object_id'])\n",
        "    f = {'object_id': obj}\n",
        "    if obj in stats:\n",
        "        obj_stats = stats[obj]\n",
        "        n = obj_stats['global']['n']; mean = obj_stats['global']['mean']; M2 = obj_stats['global']['M2']\n",
        "        M3 = obj_stats['global']['M3']; M4 = obj_stats['global']['M4']\n",
        "        if n > 2 and M2 > 0:\n",
        "            skew = (np.sqrt(n) * M3) / (M2 ** 1.5)\n",
        "            kurtosis = (n * M4) / (M2 * M2) - 3\n",
        "        else:\n",
        "            skew = 0.0; kurtosis = 0.0\n",
        "        f['n_obs'] = n; f['t_span'] = obj_stats['t_max'] - obj_stats['t_min']\n",
        "        f['flux_all_mean'] = mean; f['flux_all_std'] = np.sqrt(M2/(n-1)) if n>1 else 0.0\n",
        "        f['flux_all_skew'] = skew; f['flux_all_kurtosis'] = kurtosis\n",
        "        f['flux_det_frac'] = obj_stats['global']['det_sum']/n if n>0 else 0.0\n",
        "        f['n_bands'] = len(obj_stats['bands'])\n",
        "        for band in range(6):\n",
        "            prefix = f\"pb{band}\"\n",
        "            if band in obj_stats['band_stats']:\n",
        "                bs = obj_stats['band_stats'][band]\n",
        "                nb = bs['n']; mean_b = bs['mean']; M2_b = bs['M2']\n",
        "                M3_b = bs['M3']; M4_b = bs['M4']\n",
        "                if nb > 2 and M2_b > 0:\n",
        "                    skew_b = (np.sqrt(nb) * M3_b) / (M2_b ** 1.5)\n",
        "                    kurt_b = (nb * M4_b) / (M2_b * M2_b) - 3\n",
        "                else:\n",
        "                    skew_b = 0.0; kurt_b = 0.0\n",
        "                f[f'{prefix}_mean'] = mean_b\n",
        "                f[f'{prefix}_std'] = np.sqrt(M2_b/(nb-1)) if nb>1 else 0.0\n",
        "                f[f'{prefix}_min'] = bs['min']; f[f'{prefix}_max'] = bs['max']\n",
        "                f[f'{prefix}_skew'] = skew_b; f[f'{prefix}_kurtosis'] = kurt_b\n",
        "                f[f'{prefix}_det_frac'] = bs['det_sum']/nb if nb>0 else 0.0\n",
        "            else:\n",
        "                f[f'{prefix}_mean'] = 0.0; f[f'{prefix}_std']=0.0; f[f'{prefix}_min']=0.0\n",
        "                f[f'{prefix}_max']=0.0; f[f'{prefix}_skew']=0.0; f[f'{prefix}_kurtosis']=0.0; f[f'{prefix}_det_frac']=0.0\n",
        "    else:\n",
        "        f.update({'n_obs':0,'t_span':0,'flux_all_mean':0.0,'flux_all_std':0.0,'flux_all_skew':0.0,\n",
        "                  'flux_all_kurtosis':0.0,'flux_det_frac':0.0,'n_bands':0})\n",
        "        for band in range(6):\n",
        "            prefix = f\"pb{band}\"\n",
        "            f[f'{prefix}_mean'] = 0.0; f[f'{prefix}_std']=0.0; f[f'{prefix}_min']=0.0\n",
        "            f[f'{prefix}_max']=0.0; f[f'{prefix}_skew']=0.0; f[f'{prefix}_kurtosis']=0.0; f[f'{prefix}_det_frac']=0.0\n",
        "    feature_list.append(f)\n",
        "\n",
        "features_df = pd.DataFrame(feature_list)\n",
        "data = meta.merge(features_df, on='object_id', how='left')\n",
        "for col in data.columns:\n",
        "    if data[col].dtype in [np.float64, np.int64] and data[col].isnull().any():\n",
        "        data[col].fillna(data[col].median(), inplace=True)"
      ],
      "metadata": {
        "id": "BBK9NrRkB2ST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Entrenamiento de modelo MLPClassifier; ;\n",
        "## Transformación de datos;\n",
        "## División de datos en conjuntos de entrenamiento y validación; Evaluación del modelo con métricas de precisión y reporte;\n",
        "## Generación de reporte de clasificación; Codificación de etiquetas de clase para target\n",
        "## ----------------------------------------------------------------\n",
        "X = data.drop(columns=['object_id','ra','decl','gal_l','gal_b','target'])\n",
        "y = data['target']\n",
        "le = LabelEncoder()\n",
        "y_enc = le.fit_transform(y)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y_enc, test_size=0.2, stratify=y_enc, random_state=42)\n",
        "## Escalado de características\n",
        "## Ajuste y transformación de escalador para datos de entrenamiento\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(128,64,32), activation='relu', solver='adam', batch_size=32, max_iter=50, random_state=42, verbose=True)\n",
        "mlp.fit(X_train_scaled, y_train)\n",
        "y_val_pred = mlp.predict(X_val_scaled)\n",
        "print(\"Accuracy en validación:\", accuracy_score(y_val, y_val_pred))\n",
        "print(classification_report(y_val, y_val_pred, target_names=[str(c) for c in le.classes_]))\n",
        "\n",
        "joblib.dump(mlp, 'mlp_plasticc_model.pkl')\n",
        "joblib.dump(le, 'label_encoder.pkl')\n",
        "joblib.dump(scaler, 'scaler.pkl')"
      ],
      "metadata": {
        "id": "ctxpazA2CE0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Con datos extra\n",
        "\n",
        "En esta sección se quiere incluir los damas datos para comparar su importancia en los resultados obtenidos."
      ],
      "metadata": {
        "id": "jnWB_oAwBxQA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2x7G7TgC_myB",
        "outputId": "81186c1e-954e-4600-f9d4-1572bddb0c34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-2413030156>:132: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['redshift_used'].fillna(data['redshift_used'].median(), inplace=True)\n",
            "<ipython-input-4-2413030156>:136: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data[col].fillna(data[col].median(), inplace=True)\n"
          ]
        }
      ],
      "source": [
        "## Cálculo de estadísticas de luz: media, desviación, skewness, kurtosis;\n",
        "## Procesamiento por lotes de datos de curvas de luz; Operaciones matemáticas con numpy, cálculos estadísticos; Carga de datos con pandas\n",
        "## ----------------------------------------------------------------\n",
        "# 1. Carga de metadata\n",
        "meta = pd.read_csv('training_set_metadata.csv')\n",
        "\n",
        "# 2. Leer light-curve y extraer estadísticas incrementales con limpieza\n",
        "def init_stats():\n",
        "    return {'n': 0, 'mean': 0.0, 'M2': 0.0, 'M3': 0.0, 'M4': 0.0, 'min': np.inf, 'max': -np.inf, 'det_sum': 0}\n",
        "\n",
        "def update_moments(s, x):\n",
        "    # Asume aquí que x es valor de flujo ya filtrado; no incluye 'detected' porque\n",
        "    # sólo llamamos si detected==1.\n",
        "    n1 = s['n']\n",
        "    n = n1 + 1\n",
        "    delta = x - s['mean']\n",
        "    delta_n = delta / n\n",
        "    mean = s['mean'] + delta_n\n",
        "    M2 = s['M2'] + delta * (x - mean)\n",
        "    M3 = s['M3'] + delta * (x - mean) * (n1 - 1) - 3 * delta_n * s['M2'] if n1 > 0 else 0.0\n",
        "    M4 = s['M4'] + delta * (x - mean) * (delta * (x - mean) * (n1**2 - 3*n1 + 3) / n**2 + 6 * s['M2'] / n) if n1 > 0 else 0.0\n",
        "    s['n'] = n; s['mean'] = mean; s['M2'] = M2; s['M3'] = M3; s['M4'] = M4\n",
        "    s['min'] = min(s['min'], x); s['max'] = max(s['max'], x)\n",
        "    # s['det_sum'] se incrementa externamente al llamar sólo si detected==1\n",
        "\n",
        "stats = {}\n",
        "# Primera pasada: extraer stats por objeto, filtrando no-detecciones\n",
        "for chunk in pd.read_csv('training_set.csv.zip', compression='zip', chunksize=10**6):\n",
        "    # Si existe flux_err y queremos filtrar, podríamos:\n",
        "    # threshold_flux_err = some_value  # calcular de antemano o heurístico\n",
        "    for idx, row in chunk.iterrows():\n",
        "        obj = int(row['object_id'])\n",
        "        mjd = row['mjd']\n",
        "        band = int(row['passband'])\n",
        "        flux = row['flux']\n",
        "        detected = int(row['detected'])\n",
        "        flux_err = row.get('flux_err', None)  # si existe columna\n",
        "        # 1) Excluir no-detecciones\n",
        "        if detected != 1:\n",
        "            continue\n",
        "        # 2) Opcional: filtrar por flux_err alto o flux negativo extremo\n",
        "        # if flux_err is not None and flux_err > threshold_flux_err:\n",
        "        #     continue\n",
        "        # if flux < LOWER or flux > UPPER: continue\n",
        "        if obj not in stats:\n",
        "            stats[obj] = {'t_min': mjd, 't_max': mjd, 'bands': set(),\n",
        "                          'global': init_stats(), 'band_stats': {}}\n",
        "        obj_stats = stats[obj]\n",
        "        obj_stats['t_min'] = min(obj_stats['t_min'], mjd)\n",
        "        obj_stats['t_max'] = max(obj_stats['t_max'], mjd)\n",
        "        # actualizar estadísticos globales\n",
        "        update_moments(obj_stats['global'], flux)\n",
        "        obj_stats['global']['det_sum'] = obj_stats['global'].get('det_sum', 0) + 1\n",
        "        # band_stats\n",
        "        if band not in obj_stats['band_stats']:\n",
        "            obj_stats['band_stats'][band] = init_stats()\n",
        "        update_moments(obj_stats['band_stats'][band], flux)\n",
        "        obj_stats['band_stats'][band]['det_sum'] = obj_stats['band_stats'][band].get('det_sum', 0) + 1\n",
        "        obj_stats['bands'].add(band)\n",
        "\n",
        "# 3. Construcción de DataFrame de features\n",
        "feature_list = []\n",
        "for idx, row in meta.iterrows():\n",
        "    obj = int(row['object_id'])\n",
        "    f = {'object_id': obj}\n",
        "    if obj in stats:\n",
        "        obj_stats = stats[obj]\n",
        "        n = obj_stats['global']['n']\n",
        "        M2 = obj_stats['global']['M2']\n",
        "        M3 = obj_stats['global']['M3']\n",
        "        M4 = obj_stats['global']['M4']\n",
        "        # Calcular skew y kurtosis robustos si es posible\n",
        "        if n > 2 and M2 > 0:\n",
        "            skew = (np.sqrt(n) * M3) / (M2 ** 1.5)\n",
        "            kurtosis = (n * M4) / (M2 * M2) - 3\n",
        "        else:\n",
        "            skew = 0.0; kurtosis = 0.0\n",
        "        f['n_obs'] = n\n",
        "        f['t_span'] = obj_stats['t_max'] - obj_stats['t_min']\n",
        "        f['flux_all_mean'] = obj_stats['global']['mean']\n",
        "        f['flux_all_std'] = np.sqrt(M2/(n-1)) if n>1 else 0.0\n",
        "        f['flux_all_skew'] = skew\n",
        "        f['flux_all_kurtosis'] = kurtosis\n",
        "        # fracción de detecciones: en PLAsTiCC, si n es conteo de detecciones tras filtrar,\n",
        "        # flux_det_frac podría equivaler a 1.0; si se quiere relación con total de observaciones,\n",
        "        # habría que llevar otro contador.\n",
        "        f['flux_det_frac'] = obj_stats['global']['det_sum'] / n if n>0 else 0.0\n",
        "        f['n_bands'] = len(obj_stats['bands'])\n",
        "        for band in range(6):\n",
        "            prefix = f\"pb{band}\"\n",
        "            if band in obj_stats['band_stats']:\n",
        "                bs = obj_stats['band_stats'][band]\n",
        "                nb = bs['n']\n",
        "                M2_b = bs['M2']\n",
        "                M3_b = bs['M3']\n",
        "                M4_b = bs['M4']\n",
        "                if nb > 2 and M2_b > 0:\n",
        "                    skew_b = (np.sqrt(nb) * M3_b) / (M2_b ** 1.5)\n",
        "                    kurt_b = (nb * M4_b) / (M2_b * M2_b) - 3\n",
        "                else:\n",
        "                    skew_b = 0.0; kurt_b = 0.0\n",
        "                f[f'{prefix}_mean'] = bs['mean']\n",
        "                f[f'{prefix}_std'] = np.sqrt(M2_b/(nb-1)) if nb>1 else 0.0\n",
        "                f[f'{prefix}_min'] = bs['min']\n",
        "                f[f'{prefix}_max'] = bs['max']\n",
        "                f[f'{prefix}_skew'] = skew_b\n",
        "                f[f'{prefix}_kurtosis'] = kurt_b\n",
        "                f[f'{prefix}_det_frac'] = bs['det_sum'] / nb if nb>0 else 0.0\n",
        "            else:\n",
        "                f[f'{prefix}_mean'] = 0.0; f[f'{prefix}_std']=0.0; f[f'{prefix}_min']=0.0\n",
        "                f[f'{prefix}_max']=0.0; f[f'{prefix}_skew']=0.0; f[f'{prefix}_kurtosis']=0.0; f[f'{prefix}_det_frac']=0.0\n",
        "    else:\n",
        "        # Sin datos de serie temporal tras filtrar; rellenar con ceros/neutros\n",
        "        f.update({'n_obs':0,'t_span':0,'flux_all_mean':0.0,'flux_all_std':0.0,\n",
        "                  'flux_all_skew':0.0,'flux_all_kurtosis':0.0,'flux_det_frac':0.0,'n_bands':0})\n",
        "        for band in range(6):\n",
        "            prefix = f\"pb{band}\"\n",
        "            f[f'{prefix}_mean'] = 0.0; f[f'{prefix}_std']=0.0; f[f'{prefix}_min']=0.0\n",
        "            f[f'{prefix}_max']=0.0; f[f'{prefix}_skew']=0.0; f[f'{prefix}_kurtosis']=0.0; f[f'{prefix}_det_frac']=0.0\n",
        "    feature_list.append(f)\n",
        "\n",
        "features_df = pd.DataFrame(feature_list)\n",
        "\n",
        "# 4. Merge con metadata\n",
        "data = meta.merge(features_df, on='object_id', how='left')\n",
        "\n",
        "# 5. Incorporar las nuevas características de redshift/extinción:\n",
        "# Asumiendo que meta contiene columnas: hostgal_specz, hostgal_photoz, hostgal_photoz_err, distmod, mwebv\n",
        "# a) Crear columna redshift_used apuntando a specz cuando exista, sino a photoz:\n",
        "data['redshift_used'] = data['hostgal_specz'].fillna(data['hostgal_photoz'])\n",
        "# Si hay NaN en redshift_used, rellenar con mediana:\n",
        "data['redshift_used'].fillna(data['redshift_used'].median(), inplace=True)\n",
        "# b) Rellenar NaNs en hostgal_photoz, hostgal_photoz_err, distmod, mwebv con medianas:\n",
        "for col in ['hostgal_photoz', 'hostgal_photoz_err', 'distmod', 'mwebv']:\n",
        "    if col in data.columns:\n",
        "        data[col].fillna(data[col].median(), inplace=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Entrenamiento de modelo MLPClassifier; Escalado de características;\n",
        "## Ajuste y transformación de escalador para datos de entrenamiento;\n",
        "## Transformación de datos; División de datos en conjuntos de entrenamiento y validación; Evaluación del modelo con métricas de precisión y reporte; Generación de reporte de clasificación; Codificación de etiquetas de clase para target\n",
        "## ----------------------------------------------------------------\n",
        "# 6. Preparar X e y\n",
        "# Eliminar columnas no deseadas. Ahora NO eliminar hostgal_*, distmod, mwebv ni redshift_used.\n",
        "drop_cols = ['object_id', 'ra', 'decl', 'gal_l', 'gal_b', 'target']\n",
        "X = data.drop(columns=[c for c in drop_cols if c in data.columns])\n",
        "y = data['target']\n",
        "\n",
        "# 7. Encoding y y división train/val\n",
        "le = LabelEncoder()\n",
        "y_enc = le.fit_transform(y)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y_enc, test_size=0.2,\n",
        "                                                  stratify=y_enc, random_state=42)\n",
        "\n",
        "# 8. Escalado\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "# 9. Entrenamiento del modelo (ejemplo MLP; se puede experimentar con RF, etc.)\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(128,64,32), activation='relu',\n",
        "                    solver='adam', batch_size=32, max_iter=50,\n",
        "                    random_state=42, verbose=True)\n",
        "mlp.fit(X_train_scaled, y_train)\n",
        "y_val_pred = mlp.predict(X_val_scaled)\n",
        "print(\"Accuracy en validación:\", accuracy_score(y_val, y_val_pred))\n",
        "print(classification_report(y_val, y_val_pred, target_names=[str(c) for c in le.classes_]))\n",
        "\n",
        "# 10. Guardar modelos\n",
        "joblib.dump(mlp, 'mlp_plasticc_model.pkl')\n",
        "joblib.dump(le, 'label_encoder.pkl')\n",
        "joblib.dump(scaler, 'scaler.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3FgBIF5_7zk",
        "outputId": "256fc083-966d-4e49-d6e3-dd35cf3d7842"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 1.48098563\n",
            "Iteration 2, loss = 0.95101788\n",
            "Iteration 3, loss = 0.84764953\n",
            "Iteration 4, loss = 0.77621076\n",
            "Iteration 5, loss = 0.73693989\n",
            "Iteration 6, loss = 0.70288342\n",
            "Iteration 7, loss = 0.68609865\n",
            "Iteration 8, loss = 0.64840002\n",
            "Iteration 9, loss = 0.62588463\n",
            "Iteration 10, loss = 0.60997748\n",
            "Iteration 11, loss = 0.59291472\n",
            "Iteration 12, loss = 0.59360703\n",
            "Iteration 13, loss = 0.58395067\n",
            "Iteration 14, loss = 0.56981134\n",
            "Iteration 15, loss = 0.54844911\n",
            "Iteration 16, loss = 0.52528831\n",
            "Iteration 17, loss = 0.51310189\n",
            "Iteration 18, loss = 0.52815115\n",
            "Iteration 19, loss = 0.49485277\n",
            "Iteration 20, loss = 0.48535803\n",
            "Iteration 21, loss = 0.47554739\n",
            "Iteration 22, loss = 0.46617277\n",
            "Iteration 23, loss = 0.45487068\n",
            "Iteration 24, loss = 0.45044855\n",
            "Iteration 25, loss = 0.45319525\n",
            "Iteration 26, loss = 0.43375569\n",
            "Iteration 27, loss = 0.42364822\n",
            "Iteration 28, loss = 0.42059828\n",
            "Iteration 29, loss = 0.41578635\n",
            "Iteration 30, loss = 0.40788168\n",
            "Iteration 31, loss = 0.41916985\n",
            "Iteration 32, loss = 0.39724567\n",
            "Iteration 33, loss = 0.38957012\n",
            "Iteration 34, loss = 0.39624542\n",
            "Iteration 35, loss = 0.36637219\n",
            "Iteration 36, loss = 0.35769412\n",
            "Iteration 37, loss = 0.35033064\n",
            "Iteration 38, loss = 0.35444217\n",
            "Iteration 39, loss = 0.35253162\n",
            "Iteration 40, loss = 0.35338264\n",
            "Iteration 41, loss = 0.34772733\n",
            "Iteration 42, loss = 0.32716793\n",
            "Iteration 43, loss = 0.32038713\n",
            "Iteration 44, loss = 0.34190103\n",
            "Iteration 45, loss = 0.31427042\n",
            "Iteration 46, loss = 0.29831537\n",
            "Iteration 47, loss = 0.29834539\n",
            "Iteration 48, loss = 0.29875536\n",
            "Iteration 49, loss = 0.28484065\n",
            "Iteration 50, loss = 0.27975076\n",
            "Accuracy en validación: 0.7643312101910829\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           6       0.93      0.93      0.93        30\n",
            "          15       0.72      0.59      0.65        99\n",
            "          16       0.96      0.97      0.96       185\n",
            "          42       0.58      0.45      0.51       239\n",
            "          52       0.00      0.00      0.00        36\n",
            "          53       1.00      1.00      1.00         6\n",
            "          62       0.33      0.51      0.40        97\n",
            "          64       0.68      0.75      0.71        20\n",
            "          65       0.97      0.97      0.97       196\n",
            "          67       0.47      0.36      0.41        42\n",
            "          88       0.99      0.99      0.99        74\n",
            "          90       0.77      0.88      0.82       463\n",
            "          92       1.00      0.92      0.96        48\n",
            "          95       0.88      0.83      0.85        35\n",
            "\n",
            "    accuracy                           0.76      1570\n",
            "   macro avg       0.73      0.72      0.73      1570\n",
            "weighted avg       0.75      0.76      0.76      1570\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['scaler.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graficos de los objetos en cada filtro de cada Target"
      ],
      "metadata": {
        "id": "uVIRmuKRMM51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Operaciones: valores_unicos = meta['target'].unique()\n",
        "## ----------------------------------------------------------------\n",
        "# Graficos\n",
        "\n",
        "\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Definir función para graficar lightcurve de un ID y passband específicos\n",
        "def plot_lightcurve_for_id_passband(df, id_value, passband_value, target):\n",
        "    subset_id = df[df['object_id'] == id_value]\n",
        "    subset = subset_id[subset_id['passband'] == passband_value]\n",
        "\n",
        "    if subset.empty:\n",
        "        print(f\"No se encontraron datos para object_id = {id_value} y passband = {passband_value}.\")\n",
        "        return\n",
        "\n",
        "    plt.figure()\n",
        "    plt.errorbar(subset['mjd'], subset['flux'], yerr=subset['flux_err'], fmt='o', elinewidth=1, capsize=2)\n",
        "    plt.xlabel('MJD')\n",
        "    plt.ylabel('Flux')\n",
        "    plt.title(f'Lightcurve: object_id={id_value}, Band={passband_value}, Target= {target}')\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.savefig(\n",
        "    f\"/content/figuras/objeto{id_value}_banda{passband_value}.jpg\",\n",
        "    transparent=False,\n",
        "    bbox_inches='tight',\n",
        "    facecolor='white'\n",
        "    )\n",
        "    plt.close()\n",
        "\n",
        "lc = pd.read_csv('training_set.csv.zip', compression='zip')\n",
        "meta = pd.read_csv('training_set_metadata.csv')\n",
        "\n",
        "valores_unicos = meta['target'].unique()\n",
        "idselect = np.zeros(len(valores_unicos))\n",
        "\n",
        "# Lo uso para verificar como es la curva de luz de los target\n",
        "for i in range(len(valores_unicos)):\n",
        "    idselect[i] = meta[meta[\"target\"] == valores_unicos[i]][\"object_id\"].iloc[0]\n",
        "    dtu = lc[lc[\"object_id\"] == idselect[i]]\n",
        "    ban = dtu[\"passband\"].unique()\n",
        "    for j in range(len(ban)):\n",
        "      plot_lightcurve_for_id_passband(dtu, idselect[i], ban[j], valores_unicos[i])"
      ],
      "metadata": {
        "id": "Zr40v2rdA1nk"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testeo de datos"
      ],
      "metadata": {
        "id": "E1DUkdN_F-D2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "spGXk0QxfsLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Escalado de características; Cálculo de estadísticas de luz: media, desviación, skewness, kurtosis;\n",
        "## Procesamiento por lotes de datos de curvas de luz; Codificación de etiquetas de clase para target;\n",
        "## Operaciones matemáticas con numpy, cálculos estadísticos; Carga de datos con pandas\n",
        "## ----------------------------------------------------------------\n",
        "\n",
        "\n",
        "# 1. Cargar el modelo, el label encoder y el scaler que guardaste\n",
        "mlp = joblib.load('mlp_plasticc_model.pkl')           # tu modelo entrenado\n",
        "le = joblib.load('label_encoder.pkl')                 # LabelEncoder ajustado en train\n",
        "scaler = joblib.load('scaler.pkl')                    # StandardScaler ajustado en train\n",
        "\n",
        "# 2. Leer metadata de test\n",
        "# Ajusta la ruta si es distinto:\n",
        "metadata_test = pd.read_csv('test_set_metadata.csv.zip', compression='zip')\n",
        "metadata_test = metadata_test.head(1000)\n",
        "ids_validos = set(metadata_test['object_id'].values)\n",
        "# Esperamos que metadata_test tenga columna 'object_id' y posibles columnas extra (por si usas hostgal_*, etc.)\n",
        "# 3. Extraer estadísticas de curvas de luz de test\n",
        "# Definimos funciones de estadísticos incrementales (idénticas a las de tu entrenamiento)\n",
        "def init_stats():\n",
        "    return {'n': 0, 'mean': 0.0, 'M2': 0.0, 'M3': 0.0, 'M4': 0.0, 'min': np.inf, 'max': -np.inf, 'det_sum': 0}\n",
        "\n",
        "def update_moments(s, x, detected=None):\n",
        "    # Si en tu entrenamiento usaste detected para global['det_sum'], aquí también:\n",
        "    n1 = s['n']\n",
        "    n = n1 + 1\n",
        "    delta = x - s['mean']\n",
        "    delta_n = delta / n\n",
        "    mean = s['mean'] + delta_n\n",
        "    M2 = s['M2'] + delta * (x - mean)\n",
        "    if n1 > 0:\n",
        "        M3 = s['M3'] + delta * (x - mean) * (n1 - 1) - 3 * delta_n * s['M2']\n",
        "        M4 = s['M4'] + delta * (x - mean) * (delta * (x - mean) * (n1**2 - 3*n1 + 3) / n**2 + 6 * s['M2'] / n)\n",
        "    else:\n",
        "        M3 = 0.0\n",
        "        M4 = 0.0\n",
        "    s['n'] = n\n",
        "    s['mean'] = mean\n",
        "    s['M2'] = M2\n",
        "    s['M3'] = M3\n",
        "    s['M4'] = M4\n",
        "    s['min'] = min(s['min'], x)\n",
        "    s['max'] = max(s['max'], x)\n",
        "    # actualizar suma de detecciones si proporcionaste detected\n",
        "    if detected is not None:\n",
        "        s['det_sum'] = s.get('det_sum', 0) + int(detected)\n",
        "\n",
        "# Recorremos todos los archivos de test de curvas de luz. Por ejemplo, si hay test_set_batch1.csv.zip, test_set_batch2...\n",
        "# Ajusta la lista según tus archivos:\n",
        "test_curve_files = ['test_set_batch1.csv.zip']  # agrega más si es necesario\n",
        "\n",
        "# stats_test: dict con key=object_id, value: dict con t_min, t_max, bands, global stats, band_stats\n",
        "stats_test = {}\n",
        "for file in test_curve_files:\n",
        "    # Leer en chunks (por ejemplo, chunksize=10**6 si es grande)\n",
        "    for chunk in pd.read_csv(file, compression='zip', chunksize=10**6):\n",
        "        # Asegúrate de que las columnas coincidan: object_id, mjd, passband, flux, detected\n",
        "        chunk = chunk[chunk['object_id'].isin(ids_validos)]\n",
        "        for idx, row in chunk.iterrows():\n",
        "            obj = int(row['object_id'])\n",
        "            mjd = row['mjd']\n",
        "            band = int(row['passband'])\n",
        "            flux = row['flux']\n",
        "            detected = row.get('detected', None)  # si existe; en test a veces no hay etiqueta, pero normalmente sí hay columna detected\n",
        "            # Si en tu pipeline de entrenamiento no filtrabas por detected (tomabas todos), seguimos igual.\n",
        "            if obj not in stats_test:\n",
        "                stats_test[obj] = {\n",
        "                    't_min': mjd,\n",
        "                    't_max': mjd,\n",
        "                    'bands': set(),\n",
        "                    'global': init_stats(),\n",
        "                    'band_stats': {}\n",
        "                }\n",
        "            obj_stats = stats_test[obj]\n",
        "            obj_stats['t_min'] = min(obj_stats['t_min'], mjd)\n",
        "            obj_stats['t_max'] = max(obj_stats['t_max'], mjd)\n",
        "            # actualizar global\n",
        "            update_moments(obj_stats['global'], flux, detected)\n",
        "            # band stats\n",
        "            if band not in obj_stats['band_stats']:\n",
        "                obj_stats['band_stats'][band] = init_stats()\n",
        "            update_moments(obj_stats['band_stats'][band], flux, detected)\n",
        "            obj_stats['bands'].add(band)\n",
        "\n",
        "# 4. Construir DataFrame de características para test\n",
        "feature_list = []\n",
        "for idx, row in metadata_test.iterrows():\n",
        "    obj = int(row['object_id'])\n",
        "    f = {'object_id': obj}\n",
        "    if obj in stats_test:\n",
        "        obj_stats = stats_test[obj]\n",
        "        # Estadísticos globales\n",
        "        n = obj_stats['global']['n']\n",
        "        M2 = obj_stats['global']['M2']\n",
        "        M3 = obj_stats['global']['M3']\n",
        "        M4 = obj_stats['global']['M4']\n",
        "        # Cálculo de skew y kurtosis análogo al entrenamiento\n",
        "        if n > 2 and M2 > 0:\n",
        "            skew = (np.sqrt(n) * M3) / (M2 ** 1.5)\n",
        "            kurtosis = (n * M4) / (M2 * M2) - 3\n",
        "        else:\n",
        "            skew = 0.0\n",
        "            kurtosis = 0.0\n",
        "        f['n_obs'] = n\n",
        "        f['t_span'] = obj_stats['t_max'] - obj_stats['t_min']\n",
        "        f['flux_all_mean'] = obj_stats['global']['mean']\n",
        "        f['flux_all_std'] = np.sqrt(M2/(n-1)) if n > 1 else 0.0\n",
        "        f['flux_all_skew'] = skew\n",
        "        f['flux_all_kurtosis'] = kurtosis\n",
        "        # fracción de detecciones\n",
        "        det_sum = obj_stats['global'].get('det_sum', None)\n",
        "        if det_sum is not None and n > 0:\n",
        "            f['flux_det_frac'] = det_sum / n\n",
        "        else:\n",
        "            # Si en test no viene 'detected' o no la usaste, podrías fijar 1.0 o 0.0 según convenga. Aquí:\n",
        "            f['flux_det_frac'] = obj_stats['global'].get('det_sum', 0) / n if n > 0 else 0.0\n",
        "        f['n_bands'] = len(obj_stats['bands'])\n",
        "        # Estadísticos por banda (suponiendo 6 bandas, 0..5)\n",
        "        for band in range(6):\n",
        "            prefix = f\"pb{band}\"\n",
        "            if band in obj_stats['band_stats']:\n",
        "                bs = obj_stats['band_stats'][band]\n",
        "                nb = bs['n']\n",
        "                M2_b = bs['M2']\n",
        "                M3_b = bs['M3']\n",
        "                M4_b = bs['M4']\n",
        "                if nb > 2 and M2_b > 0:\n",
        "                    skew_b = (np.sqrt(nb) * M3_b) / (M2_b ** 1.5)\n",
        "                    kurt_b = (nb * M4_b) / (M2_b * M2_b) - 3\n",
        "                else:\n",
        "                    skew_b = 0.0\n",
        "                    kurt_b = 0.0\n",
        "                f[f'{prefix}_mean'] = bs['mean']\n",
        "                f[f'{prefix}_std'] = np.sqrt(M2_b/(nb-1)) if nb > 1 else 0.0\n",
        "                f[f'{prefix}_min'] = bs['min']\n",
        "                f[f'{prefix}_max'] = bs['max']\n",
        "                f[f'{prefix}_skew'] = skew_b\n",
        "                f[f'{prefix}_kurtosis'] = kurt_b\n",
        "                det_sum_b = bs.get('det_sum', None)\n",
        "                if det_sum_b is not None and nb > 0:\n",
        "                    f[f'{prefix}_det_frac'] = det_sum_b / nb\n",
        "                else:\n",
        "                    f[f'{prefix}_det_frac'] = bs.get('det_sum', 0) / nb if nb > 0 else 0.0\n",
        "            else:\n",
        "                # Sin observaciones en esta banda\n",
        "                f[f'{prefix}_mean'] = 0.0\n",
        "                f[f'{prefix}_std'] = 0.0\n",
        "                f[f'{prefix}_min'] = 0.0\n",
        "                f[f'{prefix}_max'] = 0.0\n",
        "                f[f'{prefix}_skew'] = 0.0\n",
        "                f[f'{prefix}_kurtosis'] = 0.0\n",
        "                f[f'{prefix}_det_frac'] = 0.0\n",
        "    else:\n",
        "        # Objeto sin curvas en test (raro, pero para robustez)\n",
        "        f.update({\n",
        "            'n_obs': 0,\n",
        "            't_span': 0,\n",
        "            'flux_all_mean': 0.0,\n",
        "            'flux_all_std': 0.0,\n",
        "            'flux_all_skew': 0.0,\n",
        "            'flux_all_kurtosis': 0.0,\n",
        "            'flux_det_frac': 0.0,\n",
        "            'n_bands': 0\n",
        "        })\n",
        "        for band in range(6):\n",
        "            prefix = f\"pb{band}\"\n",
        "            f[f'{prefix}_mean'] = 0.0\n",
        "            f[f'{prefix}_std'] = 0.0\n",
        "            f[f'{prefix}_min'] = 0.0\n",
        "            f[f'{prefix}_max'] = 0.0\n",
        "            f[f'{prefix}_skew'] = 0.0\n",
        "            f[f'{prefix}_kurtosis'] = 0.0\n",
        "            f[f'{prefix}_det_frac'] = 0.0\n",
        "    feature_list.append(f)\n",
        "\n",
        "features_test_df = pd.DataFrame(feature_list)\n",
        "\n",
        "# 5. Merge con metadata_test\n",
        "data_test = metadata_test.merge(features_test_df, on='object_id', how='left')\n",
        "\n",
        "# 6. Incorporar columnas extra si usas hostgal_specz, hostgal_photoz, distmod, mwebv, etc.\n",
        "# Si en test se incluyen, repite mismo procesamiento que en entrenamiento:\n",
        "if 'hostgal_specz' in data_test.columns and 'hostgal_photoz' in data_test.columns:\n",
        "    data_test['redshift_used'] = data_test['hostgal_specz'].fillna(data_test['hostgal_photoz'])\n",
        "    data_test['redshift_used'].fillna(data_test['redshift_used'].median(), inplace=True)\n",
        "    for col in ['hostgal_photoz', 'hostgal_photoz_err', 'distmod', 'mwebv']:\n",
        "        if col in data_test.columns:\n",
        "            data_test[col].fillna(data_test[col].median(), inplace=True)\n",
        "\n",
        "# 7. Seleccionar X_test con mismas columnas que en entrenamiento\n",
        "# Recuerda: en entrenamiento habías hecho:\n",
        "# X = data.drop(columns=['object_id','ra','decl','gal_l','gal_b','target'])\n",
        "# Aquí, en test no habrá columna 'target'. Asegúrate de dropear las mismas columnas redundantes.\n",
        "cols_drop = ['object_id', 'ra', 'decl', 'gal_l', 'gal_b', 'target']\n",
        "X_test = data_test.drop(columns=[c for c in cols_drop if c in data_test.columns])\n",
        "\n",
        "# 8. Imputar NaNs en X_test: rellenar con medianas de cada columna (calculadas en entrenamiento idealmente).\n",
        "# OJO: si quieres máxima fidelidad, deberías usar en cada columna la misma mediana que usaste en entrenamiento.\n",
        "# Pero si no almacenaste esas medianas, una aproximación es rellenar con la mediana de X_test.\n",
        "for col in X_test.columns:\n",
        "    if X_test[col].dtype in [np.float64, np.int64] and X_test[col].isnull().any():\n",
        "        med = X_test[col].median()\n",
        "        X_test[col].fillna(med, inplace=True)\n",
        "\n",
        "# 9. Escalado usando el StandardScaler entrenado:\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 10. predecir probabilidades\n",
        "proba = mlp.predict_proba(X_test_scaled)  # array shape (n_objetos_test, 14)\n",
        "\n",
        "# 11. Construir DataFrame de salida\n",
        "# Obtener nombres de clases desde LabelEncoder. Por ejemplo, le.classes_ podría ser array(['15', '42', ...]) o int/string.\n",
        "class_names = [f\"Class_{cls}\" for cls in le.classes_]  # conviertele a str para usar en columnas\n",
        "# O, si prefieres nombres como \"class_0\",\"class_1\",...:\n",
        "# class_names = [f'class_{i}' for i in range(len(le.classes_))]\n",
        "\n",
        "df_out = pd.DataFrame(proba, columns=class_names)\n",
        "df_out.insert(0, 'object_id', data_test['object_id'].values)\n",
        "df_out.insert(1, 'class_99', 1 - df_out[class_names].sum(axis=1))\n",
        "rdf_out = df_out.round(3)\n",
        "\n",
        "# 12. (Opcional) Si la competición pide otra forma (por ejemplo, en formato long: filas duplicadas para cada target),\n",
        "# puedes transformar df_out en long con pd.melt, pero la mayoría de competiciones PLAsTiCC esperan wide:\n",
        "# object_id, prob_class0, prob_class1, ..., prob_class13.\n",
        "\n",
        "# 13. Guardar el CSV de Submission\n",
        "rdf_out.to_csv('submission.csv', index=False)\n",
        "\n",
        "# 14. Mostrar un vistazo\n",
        "rdf_out\n"
      ],
      "metadata": {
        "id": "6ixWLTzuF7Yu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 808
        },
        "outputId": "981c5dba-3346-479a-f8c2-165c044b5248"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-4170308700>:185: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data_test['redshift_used'].fillna(data_test['redshift_used'].median(), inplace=True)\n",
            "<ipython-input-17-4170308700>:188: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data_test[col].fillna(data_test[col].median(), inplace=True)\n",
            "<ipython-input-17-4170308700>:203: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(med, inplace=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     object_id  class_99  Class_6  Class_15  Class_16  Class_42  Class_52  \\\n",
              "0           13       0.0      0.0     0.000       0.0       0.0       0.0   \n",
              "1           14       0.0      0.0     0.000       0.0       0.0       0.0   \n",
              "2           17       0.0      0.0     0.000       0.0       0.0       0.0   \n",
              "3           23       0.0      0.0     0.000       0.0       0.0       0.0   \n",
              "4           34       0.0      0.0     0.000       0.0       0.0       0.0   \n",
              "..         ...       ...      ...       ...       ...       ...       ...   \n",
              "995      10180       0.0      0.0     0.000       0.0       0.0       0.0   \n",
              "996      10213       0.0      0.0     0.000       0.0       0.0       0.0   \n",
              "997      10218       0.0      0.0     0.389       0.0       0.0       0.0   \n",
              "998      10228       0.0      0.0     0.000       0.0       0.0       0.0   \n",
              "999      10244       0.0      0.0     0.000       0.0       0.0       0.0   \n",
              "\n",
              "     Class_53  Class_62  Class_64  Class_65  Class_67  Class_88  Class_90  \\\n",
              "0         0.0       0.0       0.0     0.234       0.0     0.766       0.0   \n",
              "1         0.0       0.0       0.0     0.000       0.0     1.000       0.0   \n",
              "2         0.0       0.0       0.0     0.000       0.0     1.000       0.0   \n",
              "3         0.0       0.0       0.0     0.292       0.0     0.708       0.0   \n",
              "4         0.0       0.0       0.0     1.000       0.0     0.000       0.0   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "995       0.0       0.0       0.0     0.000       0.0     1.000       0.0   \n",
              "996       0.0       0.0       0.0     0.000       0.0     1.000       0.0   \n",
              "997       0.0       0.0       0.0     0.005       0.0     0.606       0.0   \n",
              "998       0.0       0.0       0.0     0.062       0.0     0.938       0.0   \n",
              "999       0.0       0.0       0.0     0.000       0.0     1.000       0.0   \n",
              "\n",
              "     Class_92  Class_95  \n",
              "0         0.0       0.0  \n",
              "1         0.0       0.0  \n",
              "2         0.0       0.0  \n",
              "3         0.0       0.0  \n",
              "4         0.0       0.0  \n",
              "..        ...       ...  \n",
              "995       0.0       0.0  \n",
              "996       0.0       0.0  \n",
              "997       0.0       0.0  \n",
              "998       0.0       0.0  \n",
              "999       0.0       0.0  \n",
              "\n",
              "[1000 rows x 16 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2aa7c7b4-9207-4c66-8bf6-486d14a04c73\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>object_id</th>\n",
              "      <th>class_99</th>\n",
              "      <th>Class_6</th>\n",
              "      <th>Class_15</th>\n",
              "      <th>Class_16</th>\n",
              "      <th>Class_42</th>\n",
              "      <th>Class_52</th>\n",
              "      <th>Class_53</th>\n",
              "      <th>Class_62</th>\n",
              "      <th>Class_64</th>\n",
              "      <th>Class_65</th>\n",
              "      <th>Class_67</th>\n",
              "      <th>Class_88</th>\n",
              "      <th>Class_90</th>\n",
              "      <th>Class_92</th>\n",
              "      <th>Class_95</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.234</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.766</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>17</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>23</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.292</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.708</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>34</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>10180</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>10213</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>10218</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.389</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.606</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>10228</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.062</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.938</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>10244</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 16 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2aa7c7b4-9207-4c66-8bf6-486d14a04c73')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2aa7c7b4-9207-4c66-8bf6-486d14a04c73 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2aa7c7b4-9207-4c66-8bf6-486d14a04c73');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6bb17b98-ca9f-4245-81b6-22466e5ef707\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6bb17b98-ca9f-4245-81b6-22466e5ef707')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6bb17b98-ca9f-4245-81b6-22466e5ef707 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_449f67d7-fd58-4744-80a1-bdbbe9875a40\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('rdf_out')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_449f67d7-fd58-4744-80a1-bdbbe9875a40 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('rdf_out');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "rdf_out",
              "summary": "{\n  \"name\": \"rdf_out\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"object_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2927,\n        \"min\": 13,\n        \"max\": 10244,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          5135,\n          7246,\n          7282\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class_99\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Class_6\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.027481099155798324,\n        \"min\": 0.0,\n        \"max\": 0.869,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.001\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Class_15\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.27871314450689627,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 58,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Class_16\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06252794299075123,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Class_42\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12997364127555205,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 32,\n        \"samples\": [\n          0.978\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Class_52\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Class_53\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.004143003195204656,\n        \"min\": 0.0,\n        \"max\": 0.131,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Class_62\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Class_64\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Class_65\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.39373720838684767,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 121,\n        \"samples\": [\n          0.01\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Class_67\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Class_88\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.45533247639945573,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 131,\n        \"samples\": [\n          0.445\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Class_90\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00240333102172799,\n        \"min\": 0.0,\n        \"max\": 0.076,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.076\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Class_92\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06315540484520073,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Class_95\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dNW7feBVfCkT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Operaciones: df_out.to_csv('sample_submission_check.csv', index\n",
        "## ----------------------------------------------------------------\n",
        "df_out.to_csv('sample_submission_check.csv', index=False)"
      ],
      "metadata": {
        "id": "Ji2qnagWJ15V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Este fue un intento fallido de analizar propiedades estadisticas por seciones de la curva de Luz"
      ],
      "metadata": {
        "id": "4O5SJGc2Uj-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Carga de datos con pandas\n",
        "## ----------------------------------------------------------------\n",
        "lc = pd.read_csv('training_set.csv.zip', compression='zip')\n",
        "meta = pd.read_csv('training_set_metadata.csv')\n",
        "\n",
        "id_vu = meta[\"object_id\"].unique()\n",
        "\n",
        "nombres  = [\"mean\", \"std\", \"skew\", \"kur\"]\n",
        "arrC = [ f\"{k}{nombres[i]}band{j}\"  for j in range(6) for i in range(len(nombres))  for k in range(3) ]\n",
        "dfstat = pd.DataFrame(columns=arrC)\n",
        "\n",
        "listfil = []\n",
        "\n",
        "for i in range(len(id_vu)):\n",
        "  aux = []\n",
        "  dtu = lc[lc[\"object_id\"] == id_vu[i]]\n",
        "  ban = np.sort( dtu[\"passband\"].unique())\n",
        "  for j in range(len(ban)):\n",
        "    flux = np.array(dtu[dtu[\"passband\"] == ban[j]][\"flux\"].tolist())\n",
        "    mjd = np.array(dtu[dtu[\"passband\"] == ban[j]][\"mjd\"].tolist())\n",
        "    res = np.zeros(len(mjd) - 1)\n",
        "\n",
        "    for k in range(len(mjd) - 1):\n",
        "      res[k] = np.abs(mjd[k] - mjd[k+1])\n",
        "\n",
        "    if len(res) < 6:\n",
        "      break\n",
        "\n",
        "    a = np.sort(res)[-2:len(res)]\n",
        "    f = [list(res).index(a[0]), list(res).index(a[1])]\n",
        "\n",
        "    flux1 = flux [mjd < mjd[f[1]]]\n",
        "\n",
        "    flux2 = flux[ [mjd > mjd[f[1]]][0] * [mjd < mjd[f[0]]][0] ]\n",
        "\n",
        "    flux3 = flux [ mjd > mjd[f[0]] ]\n",
        "\n",
        "    mean = [ np.mean(flux1),np.mean(flux2), np.mean(flux3) ]\n",
        "    des = [ np.std(flux1), np.std(flux2), np.std(flux3) ]\n",
        "    kt = [ kurtosis(flux1), kurtosis(flux2), kurtosis(flux3) ]\n",
        "    sk = [ skew(flux1), skew(flux2), skew(flux3)]\n",
        "\n",
        "    stats = mean+des+kt+sk\n",
        "    stats_sin_nan = [0 if np.isnan(x) else x for x in stats]\n",
        "\n",
        "    aux += stats_sin_nan\n",
        "\n",
        "  if len(aux) == 72:\n",
        "    dfstat = pd.concat([dfstat, pd.DataFrame([aux], columns=arrC)], ignore_index=True)\n",
        "\n",
        "  else:\n",
        "    listfil.append(id_vu[i])\n",
        "\n",
        "##Filtro de datos pos procesado\n",
        "\n",
        "metaf = meta[~meta[\"object_id\"].isin(listfil)]\n",
        "com = pd.concat([metaf, dfstat], axis = 1)\n",
        "rdfstat = dfstat.reset_index(drop=True)\n",
        "rmetaf = metaf.reset_index(drop=True)\n",
        "combine = pd.concat([rmetaf, rdfstat], axis = 1)\n",
        "combine_sin_nan = combine[~combine.isna().any(axis=1)]"
      ],
      "metadata": {
        "id": "NBaZJSfKN2v8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Entrenamiento de modelo MLPClassifier; Escalado de características; Ajuste y transformación de escalador para datos de entrenamiento; Transformación de datos; División de datos en conjuntos de entrenamiento y validación; Evaluación del modelo con métricas de precisión y reporte; Generación de reporte de clasificación; Codificación de etiquetas de clase para target\n",
        "## ----------------------------------------------------------------\n",
        "# parte de ML\n",
        "\n",
        "drop_cols = ['object_id', 'ra', 'decl', 'gal_l', 'gal_b', 'target']\n",
        "X = combine_sin_nan.drop(columns=[c for c in drop_cols if c in combine_sin_nan.columns])\n",
        "y = combine_sin_nan['target']\n",
        "\n",
        "\n",
        "# 7. Encoding y y división train/val\n",
        "le = LabelEncoder()\n",
        "y_enc = le.fit_transform(y)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y_enc, test_size=0.2,\n",
        "                                                  stratify=y_enc, random_state=42)\n",
        "\n",
        "# 8. Escalado\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "# 9. Entrenamiento del modelo (ejemplo MLP; se puede experimentar con RF, etc.)\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(256,128,64,32), activation='relu',\n",
        "                    solver='adam', batch_size=32, max_iter=50,\n",
        "                    random_state=42, verbose=True)\n",
        "mlp.fit(X_train_scaled, y_train)\n",
        "y_val_pred = mlp.predict(X_val_scaled)\n",
        "print(\"Accuracy en validación:\", accuracy_score(y_val, y_val_pred))\n",
        "print(classification_report(y_val, y_val_pred, target_names=[str(c) for c in le.classes_]))\n"
      ],
      "metadata": {
        "id": "kBnmUpDgOOgm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}